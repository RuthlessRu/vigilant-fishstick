\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Introduction}
Every day, millions of people interact with digital devices that can do amazing 
things - playing music, answering questions, and helping us stay organized. 
Although these technologies play a huge part in our lives, they are unable to 
understand how humans feel. 

For this reason, we strive to develop a deep learning model that can classify 
emotions in human speech. This would allow us to have more enhanced 
human-machine interactions. For example, a person's favorite playlist could 
change their song choice by adapting to their emotions in real-time. Another 
example is that virtual assistants could respond to users based on their 
emotional state. Being able to offer mental health support to people at their 
lowest point can potentially save lives and prevent disasters such as school 
shootings or suicides.

While steering toward the future, we are inevitably becoming more reliant on 
digital interfaces in our daily lives. For this reason, the ability to detect 
emotions is essential if we want to create more enriched lifestyles for the 
majority of the populace.

To achieve this, our general approach is to use a CRNN to analyze audio data. 
This type of model allows us to automate the feature extraction process and 
also handle the complexities of audio signals. Moreover, many previous studies 
have shown that CRNNs perform well in similar tasks of audio recognition.

\end{document}